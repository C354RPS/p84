{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo dos relatórios dos diversos Vendors (utilizando LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.__version__\n",
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from configparser import ConfigParser, ExtendedInterpolation\n",
    "import httpx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "from datetime import datetime\n",
    "\n",
    "config = ConfigParser(interpolation=ExtendedInterpolation())\n",
    "config.read('config-v1.x.ini', 'UTF-8')\n",
    "\n",
    "http_client = httpx.Client(verify='petrobras-ca-root.pem')\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=config['TST']['API_KEY_MODELOS_TEXTO'],\n",
    "    api_version=config['OPENAI']['OPENAI_API_VERSION'],\n",
    "    azure_endpoint=config['TST']['LITELLM_BASE_URL'],\n",
    "    http_client=http_client\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carrega Dados Básicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the correct path to the Excel file\n",
    "excel_filename = 'C:/Users/ELXY/Documents/Codigos/Python/P84_85/DadosBasicos/dados_basicos.xlsx'\n",
    "\n",
    "# Read the Excel file\n",
    "df_db = pd.read_excel(excel_filename, sheet_name=0)  # sheet_name=0 reads the first sheet\n",
    "df_db = df_db.fillna('')\n",
    "# display(df_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200 OK]>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consulta API para listar modelos\n",
    "models_resp = http_client.get(config['TST']['LITELLM_BASE_URL'] + '/models', headers={\n",
    "    'api-key': config['TST']['API_KEY_MODELOS_TEXTO'],\n",
    "    'Authorization': 'Bearer ' + config['TST']['API_KEY_MODELOS_TEXTO']\n",
    "})\n",
    "models_resp.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models = [m['id'] for m in models_resp.json()['data']]\n",
    "len(all_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['claude-3-5-haiku-20241022-v1',\n",
       " 'claude-3-7-sonnet-20250219',\n",
       " 'claude-instant-v1',\n",
       " 'claude-v2',\n",
       " 'claude-v2.1',\n",
       " 'claude-v3-haiku',\n",
       " 'claude-v3-sonnet',\n",
       " 'claude-v35-sonnet',\n",
       " 'claude-v35-sonnet-v2',\n",
       " 'command-light-v14',\n",
       " 'command-r',\n",
       " 'command-r-plus',\n",
       " 'command-v14',\n",
       " 'dall-e-3',\n",
       " 'gpt-35-turbo-16k',\n",
       " 'gpt-4o',\n",
       " 'gpt-4o-2024-08-06',\n",
       " 'gpt-4o-mini',\n",
       " 'llama3-1-405b-instruct-v1',\n",
       " 'llama3-1-70b-instruct-v1',\n",
       " 'llama3-1-8b-instruct-v1',\n",
       " 'llama3-2-11b-instruct-v1',\n",
       " 'llama3-2-1b-instruct-v1',\n",
       " 'llama3-2-3b-instruct-v1',\n",
       " 'llama3-2-90b-instruct-v1',\n",
       " 'llama3-3-70b-instruct-v1',\n",
       " 'llama3-70b-instruct',\n",
       " 'llama3-8b-instruct',\n",
       " 'mistral-7b-instruct',\n",
       " 'mistral-large',\n",
       " 'mistral-small',\n",
       " 'mixtral-8x7b-instruct',\n",
       " 'nova-lite-v1',\n",
       " 'nova-micro-v1',\n",
       " 'nova-pro-v1',\n",
       " 'stable-diffusion-xl-v1']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelos de chat\n",
    "models_chat = sorted(m for m in all_models if 'embedding' not in m)\n",
    "models_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining a function to send the prompt to the ChatGPT model\n",
    "# More info : https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?pivots=programming-language-chat-completions\n",
    "def send_message(messages, engine, max_response_tokens=500):\n",
    "    response = client.chat.completions.create(\n",
    "        model=engine,\n",
    "        messages=messages,\n",
    "        # temperature=0.5,\n",
    "        max_tokens=max_response_tokens,\n",
    "        # top_p=0.9,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# Defining a function to print out the conversation in a readable format\n",
    "def print_conversation(messages):\n",
    "    for message in messages:\n",
    "        print(f\"[{message['role'].upper()}]\")\n",
    "        print(message['content'])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrair texto do PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_texto_pdf(caminho_pdf):\n",
    "    \"\"\"Extrai texto de um arquivo PDF\"\"\"\n",
    "    with open(caminho_pdf, 'rb') as arquivo:\n",
    "        leitor_pdf = PyPDF2.PdfReader(arquivo)\n",
    "        texto_total = ''\n",
    "        \n",
    "        # Iterando sobre cada página do PDF\n",
    "        for pagina in leitor_pdf.pages:\n",
    "            texto_pagina = pagina.extract_text()\n",
    "            texto_total += texto_pagina + '\\n'\n",
    "        \n",
    "        return texto_total.strip()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analisar_documento(user_message):\n",
    "    \"\"\"Analisa o documento PDF e retorna o texto extraído\"\"\" \n",
    "    base_system_message = \"Você é um assistente especializado em suprimentos para grande projetos de construção de plataformas de petróleo. Você é capaz de responder perguntas sobre suprimentos, sobre os projetos e sobre os fornecedores.\"\n",
    "    base_system_message += \" Você também é capaz de realizar resumos sobre o status de vários pacotes de equipamentos.\"\n",
    "    base_system_message += \" Peço para você realizar um resumo em 5 linhas dos principais fatos relevantes e 5 linhas dos pontos de atenção (se houver).\"\n",
    "    base_system_message += \" Não há necessidade de preencher as 5 linhas caso não exista informação relevante nos relatórios.\"\n",
    "    base_system_message += \" O resumo deve ser feito em português. Porém não traduzir para o Português os nomes dos equipamentos e fornecedores.\"\n",
    "    system_message = base_system_message.strip()\n",
    "\n",
    "    # Verifica se o texto de entrada está vazio\n",
    "    if not user_message or len(user_message.strip()) == 0:\n",
    "        print(\"Texto de entrada está vazio.\")\n",
    "        return None\n",
    "\n",
    "    # Create the list of messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]\n",
    "\n",
    "    max_response_tokens = 500\n",
    "    model = 'claude-v35-sonnet-v2'\n",
    "    print(model.upper())\n",
    "\n",
    "    try:\n",
    "        # Inicializa response antes da chamada\n",
    "        response = None\n",
    "        \n",
    "        response = send_message(\n",
    "            messages,\n",
    "            engine=model,\n",
    "            max_response_tokens=max_response_tokens\n",
    "        )\n",
    "        \n",
    "        # Verifica se a resposta não é None\n",
    "        if response:\n",
    "            return response\n",
    "        else:\n",
    "            print(\"Não foi possível gerar resumo.\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar documento: {e}\")\n",
    "        print('-' * 30)\n",
    "        # Retorna None em caso de exceção\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_pacotes(df_db, caminho_base):\n",
    "    # Dicionário para armazenar textos dos PDFs\n",
    "    textos_pdfs = {}\n",
    "\n",
    "    # Iterar sobre os pacotes no dataframe\n",
    "    for pacote in df_db['PKG_DESCRIPTION']:\n",
    "        # Caminho completo da pasta do pacote\n",
    "        caminho_pacote = os.path.join(caminho_base, pacote)\n",
    "\n",
    "        # Verificar se a pasta existe\n",
    "        if os.path.exists(caminho_pacote) and os.path.isdir(caminho_pacote):\n",
    "            # String para armazenar texto consolidado dos PDFs deste pacote\n",
    "            texto_consolidado_pacote = \"\"\n",
    "\n",
    "            # Iterar sobre arquivos na pasta do pacote\n",
    "            for arquivo in os.listdir(caminho_pacote):\n",
    "                # Verificar se é um arquivo PDF\n",
    "                if arquivo.lower().endswith('.pdf'):\n",
    "                    caminho_completo_pdf = os.path.join(caminho_pacote, arquivo)\n",
    "                    print(f\"Lendo arquivo: {caminho_completo_pdf}\")\n",
    "\n",
    "                    try:\n",
    "                        texto_pdf = extrair_texto_pdf(caminho_completo_pdf)\n",
    "                        # Adiciona o texto do PDF ao texto consolidado, \n",
    "                        # com uma linha em branco entre os documentos\n",
    "                        texto_consolidado_pacote += texto_pdf + \"\\n\\n\"\n",
    "                    except Exception as e:\n",
    "                        print(f\"Erro ao processar {caminho_completo_pdf}: {e}\")\n",
    "\n",
    "            # Remove espaços em branco extras no início e no fim\n",
    "            texto_consolidado_pacote = texto_consolidado_pacote.strip()\n",
    "\n",
    "            # Armazena o texto consolidado no dicionário\n",
    "            textos_pdfs[pacote] = texto_consolidado_pacote\n",
    "\n",
    "    return textos_pdfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\API 610 CENTRIFUGAL PUMPS\\4_PDFsam_P84 P85 PB Mech ROE Weekly meeting_19-May-2025.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\DECK TROLLEY\\14_PDFsam_P84 P85 PB Mech ROE Weekly meeting_19-May-2025.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\FLARE SYSTEM\\10_PDFsam_P84 P85 PB Mech ROE Weekly meeting_19-May-2025.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\FRESH WATER CHLORINATION UNIT\\23_PDFsam_P84 P85Weekly meeting_22. May.25_Static.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\FRESH WATER CHLORINATION UNIT\\FRESH WATER CHLORINATION UNIT.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\FRESH WATER CHLORINATION UNIT\\P84-85 De Nora Seatrium KBR Action Tracker-21-May-25.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\NITROGEN GENERATOR UNITS\\15_PDFsam_P84 P85 PB Mech ROE Weekly meeting_19-May-2025.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\NITROGEN GENERATOR UNITS\\2025-05-21 - Progress Meeting - N2 Genarator.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\NITROGEN GENERATOR UNITS\\I-RL-3010.2S-5241-560-GK1-001_003_BI-WEEKLY REPORT_N2 GENERATOR UINIT.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\NITROGEN GENERATOR UNITS\\I-RL-3010.2T-5241-560-GK1-001_003_BI-WEEKLY REPORT_N2 GENERATOR UINIT.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\NITROGEN GENERATOR UNITS\\TQF-P84P85_N2 Cylinder Bottle.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\NON-API 610 CENTRIFUGAL PUMPS\\5_PDFsam_P84 P85 PB Mech ROE Weekly meeting_19-May-2025.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\PIG LAUNCHERS AND RECEIVERS\\18_PDFsam_P84 P85Weekly meeting_22. May.25_Static.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\PIG LAUNCHERS AND RECEIVERS\\2025-05-23 resposta email sobre ASME 31.8 vs 31.3.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\PIG LAUNCHERS AND RECEIVERS\\Minutes of Meeting 004 - Bi-Weekly Meeting - AEPL L&R.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\PIG LAUNCHERS AND RECEIVERS\\P84 - Progress Report  - 002 - 16-05-2025.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\PIG LAUNCHERS AND RECEIVERS\\P85 - Progress Report  - 001 - 16-05-2025.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\PROGRESSIVE CAVITY PUMPS\\8_PDFsam_P84 P85 PB Mech ROE Weekly meeting_19-May-2025.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\PROGRESSIVE CAVITY PUMPS\\I-RL-3010.2S-1222-560-NZA-002.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\PROGRESSIVE CAVITY PUMPS\\I-RL-3010.2T-1222-560-NZA-002.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\RECIPROCATING PUMPS\\6_PDFsam_P84 P85 PB Mech ROE Weekly meeting_19-May-2025.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\SEA WATER ELECTROCHLORINATION UNIT\\22_PDFsam_P84 P85Weekly meeting_22. May.25_Static.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\SEA WATER ELECTROCHLORINATION UNIT\\SEA WATER ELECTROCHLORINATION UNIT.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\SEA WATER LIFT PUMP\\9_PDFsam_P84 P85 PB Mech ROE Weekly meeting_19-May-2025.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\SEA WATER LIFT PUMP\\SEA WATER LIFT PUMP.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\SHELL AND TUBE HEAT EXCHANGERS (Himile)\\14_PDFsam_P84 P85Weekly meeting_22. May.25_Static.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\SHELL AND TUBE HEAT EXCHANGERS (Himile)\\kbr SHELL AND TUBE HEAT EXCHANGERS (Himile).pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\SHELL AND TUBE HEAT EXCHANGERS (Himile)\\SHELL AND TUBE HEAT EXCHANGERS (Himile).pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\SHELL AND TUBE HEAT EXCHANGERS (Asvotec)\\14_PDFsam_P84 P85Weekly meeting_22. May.25_Static.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\SHELL AND TUBE HEAT EXCHANGERS (Asvotec)\\SHELL AND TUBE HEAT EXCHANGERS (Asvotec).pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\WATER INJECTION PUMPS\\3_PDFsam_P84 P85 PB Mech ROE Weekly meeting_19-May-2025.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\WATER INJECTION PUMPS\\WATER INJECTION PUMPS.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\FRESH WATER MAKER FOR OIL DILUTION\\20_PDFsam_P84 P85Weekly meeting_22. May.25_Static.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\FRESH WATER MAKER FOR OIL DILUTION\\Minutes of Meeting 004 - Bi-Weekly Meeting - HAQT FWM (VD & OD).pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\FRESH WATER MAKER FOR OIL DILUTION\\P84 Vendor Progress Report 003.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\FRESH WATER MAKER FOR OIL DILUTION\\P85 Vendor Progress Report 003.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\PRINTED CIRCUIT HEAT EXCHANGER\\15_PDFsam_P84 P85Weekly meeting_22. May.25_Static.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\OFFSHORE CRANE\\12_PDFsam_P84 P85 PB Mech ROE Weekly meeting_19-May-2025.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\OFFSHORE CRANE\\Minutes of Meeting 004 - Bi-Weekly Meeting - NOV Crane.pdf\n",
      "Lendo arquivo: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files\\OFFSHORE CRANE\\OFFSHORE CRANE.pdf\n",
      "--------------------------------------------------------------------------------\n",
      "Processando Pacote: API 610 CENTRIFUGAL PUMPS\n",
      "CLAUDE-V35-SONNET-V2\n",
      "Resumo realizado com sucesso. Tamanho: 811 caracteres\n",
      "Resumo salvo em: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\resumos\\API 610 CENTRIFUGAL PUMPS_resumo.txt\n",
      "--------------------------------------------------------------------------------\n",
      "Processando Pacote: DECK TROLLEY\n",
      "CLAUDE-V35-SONNET-V2\n",
      "Resumo realizado com sucesso. Tamanho: 729 caracteres\n",
      "Resumo salvo em: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\resumos\\DECK TROLLEY_resumo.txt\n",
      "--------------------------------------------------------------------------------\n",
      "Processando Pacote: FLARE SYSTEM\n",
      "CLAUDE-V35-SONNET-V2\n",
      "Resumo realizado com sucesso. Tamanho: 673 caracteres\n",
      "Resumo salvo em: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\resumos\\FLARE SYSTEM_resumo.txt\n",
      "--------------------------------------------------------------------------------\n",
      "Processando Pacote: FRESH WATER CHLORINATION UNIT\n",
      "CLAUDE-V35-SONNET-V2\n",
      "Resumo realizado com sucesso. Tamanho: 834 caracteres\n",
      "Resumo salvo em: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\resumos\\FRESH WATER CHLORINATION UNIT_resumo.txt\n",
      "--------------------------------------------------------------------------------\n",
      "Processando Pacote: NITROGEN GENERATOR UNITS\n",
      "CLAUDE-V35-SONNET-V2\n",
      "Resumo realizado com sucesso. Tamanho: 1184 caracteres\n",
      "Resumo salvo em: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\resumos\\NITROGEN GENERATOR UNITS_resumo.txt\n",
      "--------------------------------------------------------------------------------\n",
      "Processando Pacote: NON-API 610 CENTRIFUGAL PUMPS\n",
      "CLAUDE-V35-SONNET-V2\n",
      "Resumo realizado com sucesso. Tamanho: 902 caracteres\n",
      "Resumo salvo em: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\resumos\\NON-API 610 CENTRIFUGAL PUMPS_resumo.txt\n",
      "--------------------------------------------------------------------------------\n",
      "Processando Pacote: PIG LAUNCHERS AND RECEIVERS\n",
      "CLAUDE-V35-SONNET-V2\n",
      "Resumo realizado com sucesso. Tamanho: 1033 caracteres\n",
      "Resumo salvo em: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\resumos\\PIG LAUNCHERS AND RECEIVERS_resumo.txt\n",
      "--------------------------------------------------------------------------------\n",
      "Processando Pacote: PROGRESSIVE CAVITY PUMPS\n",
      "CLAUDE-V35-SONNET-V2\n",
      "Resumo realizado com sucesso. Tamanho: 910 caracteres\n",
      "Resumo salvo em: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\resumos\\PROGRESSIVE CAVITY PUMPS_resumo.txt\n",
      "--------------------------------------------------------------------------------\n",
      "Processando Pacote: RECIPROCATING PUMPS\n",
      "CLAUDE-V35-SONNET-V2\n",
      "Resumo realizado com sucesso. Tamanho: 748 caracteres\n",
      "Resumo salvo em: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\resumos\\RECIPROCATING PUMPS_resumo.txt\n",
      "--------------------------------------------------------------------------------\n",
      "Processando Pacote: SEA WATER ELECTROCHLORINATION UNIT\n",
      "CLAUDE-V35-SONNET-V2\n",
      "Resumo realizado com sucesso. Tamanho: 989 caracteres\n",
      "Resumo salvo em: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\resumos\\SEA WATER ELECTROCHLORINATION UNIT_resumo.txt\n",
      "--------------------------------------------------------------------------------\n",
      "Processando Pacote: SEA WATER LIFT PUMP\n",
      "CLAUDE-V35-SONNET-V2\n",
      "Resumo realizado com sucesso. Tamanho: 1186 caracteres\n",
      "Resumo salvo em: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\resumos\\SEA WATER LIFT PUMP_resumo.txt\n",
      "--------------------------------------------------------------------------------\n",
      "Processando Pacote: SHELL AND TUBE HEAT EXCHANGERS (Himile)\n",
      "CLAUDE-V35-SONNET-V2\n",
      "Resumo realizado com sucesso. Tamanho: 971 caracteres\n",
      "Resumo salvo em: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\resumos\\SHELL AND TUBE HEAT EXCHANGERS (Himile)_resumo.txt\n",
      "--------------------------------------------------------------------------------\n",
      "Processando Pacote: SHELL AND TUBE HEAT EXCHANGERS (Asvotec)\n",
      "CLAUDE-V35-SONNET-V2\n",
      "Resumo realizado com sucesso. Tamanho: 765 caracteres\n",
      "Resumo salvo em: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\resumos\\SHELL AND TUBE HEAT EXCHANGERS (Asvotec)_resumo.txt\n",
      "--------------------------------------------------------------------------------\n",
      "Processando Pacote: WATER INJECTION PUMPS\n",
      "CLAUDE-V35-SONNET-V2\n",
      "Resumo realizado com sucesso. Tamanho: 1016 caracteres\n",
      "Resumo salvo em: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\resumos\\WATER INJECTION PUMPS_resumo.txt\n",
      "--------------------------------------------------------------------------------\n",
      "Processando Pacote: FRESH WATER MAKER FOR OIL DILUTION\n",
      "CLAUDE-V35-SONNET-V2\n",
      "Resumo realizado com sucesso. Tamanho: 926 caracteres\n",
      "Resumo salvo em: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\resumos\\FRESH WATER MAKER FOR OIL DILUTION_resumo.txt\n",
      "--------------------------------------------------------------------------------\n",
      "Processando Pacote: PRINTED CIRCUIT HEAT EXCHANGER\n",
      "CLAUDE-V35-SONNET-V2\n",
      "Resumo realizado com sucesso. Tamanho: 837 caracteres\n",
      "Resumo salvo em: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\resumos\\PRINTED CIRCUIT HEAT EXCHANGER_resumo.txt\n",
      "--------------------------------------------------------------------------------\n",
      "Processando Pacote: OFFSHORE CRANE\n",
      "CLAUDE-V35-SONNET-V2\n",
      "Resumo realizado com sucesso. Tamanho: 955 caracteres\n",
      "Resumo salvo em: C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\resumos\\OFFSHORE CRANE_resumo.txt\n",
      "\n",
      "Fim do processamento: 2025-05-26 10:11:19\n"
     ]
    }
   ],
   "source": [
    "# Uso\n",
    "caminho_base = r'C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\files'\n",
    "pasta_resumos = r\"C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\resumos\"\n",
    "textos_extraidos = processar_pacotes(df_db, caminho_base)\n",
    "\n",
    "# Analisar os textos extraídos\n",
    "for pacote, texto in textos_extraidos.items():\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Processando Pacote: {pacote}\")\n",
    "    \n",
    "    # Verifica se o texto não está vazio\n",
    "    if not texto or len(texto.strip()) == 0:\n",
    "        print(f\"Texto do pacote {pacote} está vazio. Pulando.\")\n",
    "        continue\n",
    "    \n",
    "    resumo = analisar_documento(texto)\n",
    "    \n",
    "    if resumo is None:\n",
    "        print(f\"Não foi possível gerar resumo para o pacote {pacote}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Resumo realizado com sucesso. Tamanho: {len(resumo)} caracteres\")\n",
    "    \n",
    "    # Salvar resumo em arquivo de texto\n",
    "    nome_arquivo_resumo = f\"{pacote.replace('/', '_').replace('\\\\', '_')}_resumo.txt\"\n",
    "    caminho_resumo = os.path.join(pasta_resumos, nome_arquivo_resumo)\n",
    "    \n",
    "    try:\n",
    "        with open(caminho_resumo, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"RESUMO DO RELATÓRIO: {pacote}\\n\")\n",
    "            f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "            f.write(resumo)\n",
    "        \n",
    "        print(f\"Resumo salvo em: {caminho_resumo}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao salvar resumo do pacote {pacote}: {e}\")\n",
    "\n",
    "print(f\"\\nFim do processamento: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gerando arquivo Excel com base no resumo dos arquivos txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file saved to C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\notes.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "pasta_resumos = r\"C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\ai_reports\\resumos\"\n",
    "\n",
    "# Create empty lists to store data\n",
    "data = []\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Iterate through each package in df_db\n",
    "for pkg in df_db['PKG_DESCRIPTION']:\n",
    "    filename = os.path.join(pasta_resumos, f\"{pkg}_resumo.txt\")\n",
    "    \n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "            \n",
    "            try:\n",
    "                # Extract sections\n",
    "                fatos_start = content.find('Principais fatos relevantes:')\n",
    "                pontos_start = content.find('Pontos de atenção:')\n",
    "                \n",
    "                if fatos_start != -1 and pontos_start != -1:\n",
    "                    # Get fatos relevantes and split into individual items\n",
    "                    fatos = content[fatos_start:pontos_start].replace('Principais fatos relevantes:', '').strip()\n",
    "                    fatos_list = [f.strip() for f in fatos.split('\\n') if f.strip()]\n",
    "                    \n",
    "                    # Get pontos de atenção and split into individual items\n",
    "                    pontos = content[pontos_start:].replace('Pontos de atenção:', '').strip()\n",
    "                    pontos_list = [p.strip() for p in pontos.split('\\n') if p.strip()]\n",
    "                    \n",
    "                    # Add fatos relevantes\n",
    "                    for fato in fatos_list:\n",
    "                        data.append({\n",
    "                            'PKG_DESCRIPTION': pkg,\n",
    "                            'DATE': current_date,\n",
    "                            'Tipo': 'Fato Relevante',\n",
    "                            'Descricao': fato\n",
    "                        })\n",
    "                    \n",
    "                    # Add pontos de atenção\n",
    "                    for ponto in pontos_list:\n",
    "                        data.append({\n",
    "                            'PKG_DESCRIPTION': pkg,\n",
    "                            'DATE': current_date,\n",
    "                            'Tipo': 'Ponto de Atenção',\n",
    "                            'Descricao': ponto\n",
    "                        })\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {pkg}: {str(e)}\")\n",
    "                \n",
    "# Create DataFrame\n",
    "df_notes = pd.DataFrame(data)\n",
    "\n",
    "# Save to Excel\n",
    "excel_path = r'C:\\Users\\ELXY\\Documents\\Codigos\\Python\\P84_85\\notes.xlsx'\n",
    "df_notes.to_excel(excel_path, sheet_name='notes', index=False)\n",
    "\n",
    "print(f\"Excel file saved to {excel_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
